{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84af5cfa",
   "metadata": {},
   "source": [
    "**Model_2: a CNN model building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16596570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3632748",
   "metadata": {},
   "outputs": [],
   "source": [
    "image,labels = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f991b475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "class_names=train_data.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making into dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader=DataLoader(dataset=train_data,batch_size=32,shuffle=True)\n",
    "test_dataloader=DataLoader(dataset=test_data,batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e510b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92d6986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 1, 8, 6, 6, 1, 4, 3, 9, 1, 9, 1, 2, 4, 6, 6, 4, 2, 4, 7, 5, 1, 0, 3,\n",
      "        1, 2, 0, 5, 1, 9, 3, 8])\n",
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "train_feature_batch, train_label_batch=next(iter(train_dataloader))\n",
    "print(train_label_batch)\n",
    "print(train_feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ff323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# setting up agonistic device\n",
    "import torch\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4150be25",
   "metadata": {},
   "source": [
    "The structure of CNN follows\n",
    "`Input layer` -> `[convolutional layer -> activation layer -> pooling layer]` -> `output layer`\n",
    "\n",
    "`[convolutional layer -> activation layer -> pooling layer]` can be upscaled and repeated multiple times in CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f859b8d",
   "metadata": {},
   "source": [
    "This table serves as a general guideline for choosing an appropriate model architecture based on the type of data being processed.\n",
    "\n",
    "| Problem Type | Recommended Model (Generally) | Example Library/Package |\n",
    "| :--- | :--- | :--- |\n",
    "| **Structured Data** | **Gradient Boosted Models**, **Random Forests**, XGBoost, LightGBM | `sklearn.ensemble`, `XGBoost` library |\n",
    "| (e.g., spreadsheets, row/column data) | | |\n",
    "| **Unstructured Data** | **Convolutional Neural Networks (CNNs)**, **Transformers** (e.g., for language/vision) | `torchvision.models`, `HuggingFace Transformers` |\n",
    "| (e.g., Images, Audio, Free-form Text) | | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dddd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV2(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for making CNN, we've `nn.Conv2d()` and `nn.MaxPool2d()`\n",
    "from torch import nn\n",
    "\n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    def __init__(self, input_layer:int, hidden_layer:int, output_layer:int):\n",
    "        super().__init__()\n",
    "        self.block_1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_layer,out_channels=hidden_layer, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_layer, out_channels=hidden_layer, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.block_2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_layer, out_channels=hidden_layer, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_layer, out_channels=hidden_layer,\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_layer*7*7,out_features=output_layer)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.block_1(x)\n",
    "        x=self.block_2(x)\n",
    "        x=self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model_2=FashionMNISTModelV2(input_layer=1,output_layer=len(class_names),hidden_layer=10).to(device)\n",
    "model_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555b60d",
   "metadata": {},
   "source": [
    "`in_channels (int)`:Number of channels in the input image.\n",
    "\n",
    "`out_channels (int)`: Number of channels produced by the convolution.\n",
    "\n",
    "`kernel_size (int/tuple)`:  Size of the convolving kernel/filter.\n",
    "\n",
    "`stride (int/tuple/optional)`: or tuple, optional) - How big of a step the convolving kernel takes at a time. Default: 1.\n",
    "\n",
    "`padding (int/tuple/str)`:Padding added to all four sides of input. Default: 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a3ef599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(params=model_2.parameters(),lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e42e5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy fn\n",
    "from helper_functions import accuracy_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61482f0b",
   "metadata": {},
   "source": [
    "*model_2: training loop*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c440cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model: nn.Module,\n",
    "                  data_loader: torch.utils.data.DataLoader,\n",
    "                  loss_fn: nn.modules,\n",
    "                  accuracy_fn,\n",
    "                  optimizer: torch.optim.Optimizer,\n",
    "                  device: torch.device = device):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "\n",
    "        # into device CPU\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        model.train()  # train\n",
    "        y_pred = model(X)  # forward pass\n",
    "        loss = loss_fn(y_pred, y)  # loss\n",
    "        train_loss += loss  # train loss\n",
    "        train_acc += accuracy_fn(y, y_pred.argmax(dim=1))  # train accuracy\n",
    "        optimizer.zero_grad()  # zero grad\n",
    "        loss.backward()  # backward propagation\n",
    "        optimizer.step()  # updation\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f1810",
   "metadata": {},
   "source": [
    "*model_2: testing_loop*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40ceb11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_loop(model: nn.Module,\n",
    "                 data_loader: torch.utils.data.DataLoader,\n",
    "                 loss_fn: nn.Module,\n",
    "                 accuracy_fn,\n",
    "                 device: torch.device = device\n",
    "                 ):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            test_pred = model(X)  # forward pass\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f669d6",
   "metadata": {},
   "source": [
    "*Training Testing Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25a35857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 0.53410 | Train accuracy: 80.78%\n",
      "Test loss: 0.38076 | Test accuracy: 86.33%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n",
      "Train loss: 0.34863 | Train accuracy: 87.51%\n",
      "Test loss: 0.33510 | Test accuracy: 87.91%\n",
      "\n",
      "Epoch: 2\n",
      "---------\n",
      "Train loss: 0.30969 | Train accuracy: 88.92%\n",
      "Test loss: 0.31029 | Test accuracy: 88.84%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "epochs=3\n",
    "for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch}\\n---------\")\n",
    "        training_loop(model=model_2,data_loader=train_dataloader,loss_fn=loss_fn,accuracy_fn=accuracy_fn,optimizer=optimizer,device=device)\n",
    "        testing_loop(model=model_2,data_loader=test_dataloader,loss_fn=loss_fn,accuracy_fn=accuracy_fn,device=device)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c31718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation of model_2\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def model_evaluation(model: torch.nn.Module,\n",
    "                     data_loader: torch.utils.data.DataLoader,\n",
    "                     loss_fn: torch.nn.Module,\n",
    "                     accuracy_fn):\n",
    "\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            model_pred = model(X)\n",
    "            loss += loss_fn(model_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=model_pred.argmax(dim=1))\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__,  # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cacfccc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'FashionMNISTModelV2', 'model_loss': 0.31028592586517334, 'model_acc': 88.83785942492013}\n"
     ]
    }
   ],
   "source": [
    "model_2_performance=model_evaluation(model=model_2,data_loader=test_dataloader,loss_fn=loss_fn,accuracy_fn=accuracy_fn)\n",
    "print(model_2_performance)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
