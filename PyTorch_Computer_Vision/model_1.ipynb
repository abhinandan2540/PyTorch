{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40601b8",
   "metadata": {},
   "source": [
    "**Model_1: adding some Non-Linearity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5a22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up train test data\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data=datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "\n",
    "test_data=datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=False    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac9be8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "image,labels=train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d1f720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image.squeeze())\n",
    "plt.title(label=labels)\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e7f40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "# class names of training dataset\n",
    "class_names=train_data.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67395798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "60000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data.targets))\n",
    "print(len(train_data.data))\n",
    "print(len(test_data.targets))\n",
    "print(len(test_data.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "224fed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for working with models, we'll use dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE=32\n",
    "\n",
    "train_dataloader=DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_dataloader=DataLoader(dataset=test_data,batch_size=BATCH_SIZE,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b680791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "tensor([2, 7, 9, 4, 8, 7, 7, 1, 0, 6, 4, 6, 3, 6, 8, 9, 9, 7, 1, 5, 1, 5, 2, 6,\n",
      "        4, 5, 9, 9, 8, 4, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE, what Dataloader contains\n",
    "train_feature_batch, train_labels_batch=next(iter(train_dataloader))\n",
    "print(train_feature_batch.shape)\n",
    "print(train_labels_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "919591e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# setting device\n",
    "import torch\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "52131d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 building\n",
    "from torch import nn\n",
    "class FashionMNISTV1(nn.Module):\n",
    "    def __init__(self, input_layer:int, output_layer:int, hidden_layer:int):\n",
    "        super().__init__()\n",
    "        self.layer_stack=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_layer, out_features=hidden_layer),\n",
    "            nn.ReLU(), # Activation Function\n",
    "            nn.Linear(in_features=hidden_layer, out_features=output_layer),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa5b5d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTV1(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1=FashionMNISTV1(input_layer=784,hidden_layer=10,output_layer=len(class_names))\n",
    "model_1.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3eecfa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function, optimization\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimization=torch.optim.SGD(params=model_1.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44dd74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy function\n",
    "from helper_functions import accuracy_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08959b1f",
   "metadata": {},
   "source": [
    "*Functionalizing Train Loop*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "697d2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model:nn.Module,\n",
    "                 data_loader:torch.utils.data.DataLoader,\n",
    "                 loss_fn:nn.modules,\n",
    "                 accuracy_fn,\n",
    "                 optimizer:torch.optim.Optimizer,\n",
    "                 device:torch.device=device):\n",
    "    train_loss=0\n",
    "    train_acc=0\n",
    "    for batch,(X,y) in enumerate(data_loader):\n",
    "    \n",
    "        # into device CPU\n",
    "        X=X.to(device)\n",
    "        y=y.to(device)\n",
    "\n",
    "        model.train() # train\n",
    "        y_pred=model(X) # forward pass\n",
    "        loss=loss_fn(y_pred, y) # loss\n",
    "        train_loss+=loss  # train loss\n",
    "        train_acc+=accuracy_fn(y,y_pred.argmax(dim=1)) # train accuracy\n",
    "        optimizer.zero_grad() # zero grad\n",
    "        loss.backward() # backward propagation\n",
    "        optimizer.step() # updation\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7069fd",
   "metadata": {},
   "source": [
    "*Functionalizing Testing Loop*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d0ab84e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_loop(model:nn.Module,\n",
    "                 data_loader:torch.utils.data.DataLoader,\n",
    "                 loss_fn:nn.Module,\n",
    "                 accuracy_fn,\n",
    "                 device:torch.device=device\n",
    "                 ):\n",
    "    test_loss,test_acc=0,0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X,y in data_loader:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            test_pred=model(X) # forward pass\n",
    "            test_loss+=loss_fn(test_pred,y)\n",
    "            test_acc+=accuracy_fn(y,test_pred.argmax(dim=1))\n",
    "        test_loss/=len(data_loader)\n",
    "        test_acc/=len(data_loader)\n",
    "    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584f77a",
   "metadata": {},
   "source": [
    "*Training Testing Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54879569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 0.43206 | Train accuracy: 84.54%\n",
      "Test loss: 0.43956 | Test accuracy: 84.34%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n",
      "Train loss: 0.41945 | Train accuracy: 84.94%\n",
      "Test loss: 0.45322 | Test accuracy: 83.59%\n",
      "\n",
      "Epoch: 2\n",
      "---------\n",
      "Train loss: 0.40758 | Train accuracy: 85.47%\n",
      "Test loss: 0.43578 | Test accuracy: 84.63%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "epochs=3\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "for epoch in (range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    training_loop(model=model_1,data_loader=train_dataloader,loss_fn=loss_fn,accuracy_fn=accuracy_fn,optimizer=optimization,device=device)\n",
    "    testing_loop(model=model_1,data_loader=test_dataloader,loss_fn=loss_fn,accuracy_fn=accuracy_fn,device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39655f8d",
   "metadata": {},
   "source": [
    "*model_1 evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16f9d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def model_evaluation(model: torch.nn.Module,\n",
    "                     data_loader: torch.utils.data.DataLoader,\n",
    "                     loss_fn: torch.nn.Module,\n",
    "                     accuracy_fn):\n",
    "\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            model_pred = model(X)\n",
    "            loss += loss_fn(model_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=model_pred.argmax(dim=1))\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__,  # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9c1bf73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'FashionMNISTV1', 'model_loss': 0.4357796907424927, 'model_acc': 84.63458466453675}\n"
     ]
    }
   ],
   "source": [
    "model_1_performance=model_evaluation(model=model_1,data_loader=test_dataloader,loss_fn=loss_fn,accuracy_fn=accuracy_fn)\n",
    "print(model_1_performance)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
